# ADPapers
List of Papers on Attack and Defense (AD) in AI Models

Keywords: 
- Adversarial Attack
- Robustness
- Interpretability
- Privacy

## Papers

### Natural Language Processing
1. **Semantic-Preserving Adversarial Text Attacks**. *Xinghao Yang, Weifeng Liu, James Bailey, Tianqing Zhu, Dacheng Tao, Wei Liu*. [[PDF](https://arxiv.org/abs/2108.10015)]
2. **Defense against Adversarial Attacks in NLP via Dirichlet Neighborhood Ensemble**. *Yi Zhou, Xiaoqing Zheng, Cho-Jui Hsieh, Kai-wei Chang, Xuanjing Huang*. ACL 2021. [[PDF](https://arxiv.org/abs/2006.11627)]
3. **Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger**. *Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun*. ACL 2021.  [[PDF](https://arxiv.org/abs/2105.12400)]
4. **Using Adversarial Attacks to Reveal the Statistical Bias in Machine Reading Comprehension Models**. *Jieyu Lin, Jiajie Zou and Nai Ding*. ACL 2021. [[PDF](https://arxiv.org/abs/2105.11136)] 
5. **An Empirical Study on Adversarial Attack on NMT: Languages and Positions Matter**. *Zhiyuan Zeng and Deyi Xiong*. ACL 2021. [[PDF](https://aclanthology.org/2021.acl-short.58.pdf)] 
6. **A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal Trigger’s Adversarial Attacks**. *Thai Le, Noseong Park and Dongwon Lee*. ACL 2021. [[PDF](https://arxiv.org/abs/2011.10492)]
7. **Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution**. *Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu and Maosong Sun*. ACL 2021. [[PDF](https://arxiv.org/abs/2106.06361)]
8. **Rethinking Stealthiness of Backdoor Attack against NLP Models**. *Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou and Xu Sun*. ACL 2021. [[PDF](https://aclanthology.org/2021.acl-long.431/)] 
9. **Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions**. *Daniel Rosenberg, Itai Gat, Amir Feder and Roi Reichart*. ACL 2021. [[PDF](https://arxiv.org/abs/2106.04484)] [[CODE](https://danrosenberg.github.io/rad-measure/)]
10. **CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding**. *Dong Wang, Ning Ding, Piji Li, Hai-Tao Zheng*. ACL 2021. [[PDF](https://arxiv.org/abs/2107.00440)]
11. **Differential Privacy for Text Analytics via Natural Text Sanitization**. **Xiang Yue, Minxin Du, Tianhao Wang, Yaliang Li, Huan Sun, Sherman S. M. Chow**. ACL 2021. [[PDF](https://arxiv.org/abs/2106.01221)] 
12. **Generating Fluent Adversarial Examples for Natural Languages**. *Huangzhao Zhang, Hao Zhou, Ning Miao, Lei Li*. ACL 2019. [[PDF](https://arxiv.org/abs/2007.06174)] 
13. **A Targeted Attack on Black-Box Neural Machine Translation with Parallel Data Poisoning**. *Chang Xu, Jun Wang, Yuqing Tang, Francisco Guzmán, Benjamin I. P. Rubinstein*. The Web Conference 2021. [[PDF](https://dl.acm.org/doi/abs/10.1145/3442381.3450034)] 
14. **Generating Natural Language Attacks in a Hard Label Black Box Setting**. *Rishabh Maheshwary, Saket Maheshwary, Vikram Pudi*. AAAI 2021. [[PDF](https://www.aaai.org/AAAI21Papers/AAAI-5543.MaheshwaryR.pdf)] 
15. **Beyond Accuracy: Behavioral Testing of NLP Models with CheckList**. *Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, Sameer Singh*. ACL 2020. [[PDF](https://arxiv.org/abs/2005.04118)] 
16. **Bigram and Unigram Based Text Attack via Adaptive Monotonic Heuristic Search**. *Xinghao Yang, Weifeng Liu, James Bailey, Dacheng Tao, Wei Liu*. AAAI 2021. [[PDF](https://www.aaai.org/AAAI21Papers/AAAI-4570.YangX.pdf)] 
17. **Argot: Generating Adversarial Readable Chinese Texts**. *Zihan Zhang, Mingxuan Liu, Chao Zhang, Yiming Zhang, Zhou Li, Qi Li, Haixin Duan, Donghong Sun*. IJCAI 2020. [[PDF](https://netsec.ccert.edu.cn/files/papers/ijcai20-argot.pdf)] 
18. **Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency**. *Shuhuai Ren, Yihe Deng, Kun He, Wanxiang Che*. ACL 2019. [[PDF](https://aclanthology.org/P19-1103.pdf)] 
19. **Greedy Attack and Gumbel Attack:Generating Adversarial Examples for Discrete Data**. *Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I. Jordan*. J MACH LEARN RES 2020. [[PDF](https://www.jmlr.org/papers/volume21/19-569/19-569.pdf)] 
20. **Humpty Dumpty:Controlling Word Meanings via Corpus Poisoning**. *Roei Schuster, Tal Schuster, Yoav Meri, Vitaly Shmatikov*. SP 2020. [[PDF](https://ieeexplore.ieee.org/abstract/document/9152608)] 
21. **Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment**. *Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits*. AAAI 2020. [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/6311)] 
22. **On the Robustness of Language Encoders against Grammatical Errors**. *Fan Yin, Quanyu Long, Tao Meng, Kai-Wei Chang*. ACL 2020. [[PDF](https://arxiv.org/abs/2005.05683)]
23. **Structure-Invariant Testing for Machine Translation**. *Pinjia He, Clara Meister, Zhendong Su*. ICSE 2020. [[PDF](https://ieeexplore.ieee.org/abstract/document/9284002)]
24. **Attackability Characterization of Adversarial Evasion Attack on Discrete Data**. *Wang Yutong, Han Yufei, Bao Hongyan, Shen Yun, Ma Fenglong, Li Jin, Zhang  Xiangliang*. SIGKDD 2020. [[PDF](https://dl.acm.org/doi/abs/10.1145/3394486.3403194)]
25. **Word-level Textual Adversarial Attacking as Combinatorial Optimization**. *Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu, Maosong Sun*. ACL 2020. [[PDF](https://arxiv.org/abs/1910.12196)]
26. **Bayesian Attention Belief Networks**. *Shujian Zhang, Xinjie Fan, Bo Chen, Mingyuan Zhou*. ICML 2021. [[PDF](https://arxiv.org/abs/2106.05251)][theory]
27. **Fast and Precise Certification of Transformers**. *Gregory Bonaert, Dimitar I. Dimitrov, Maximilian Baader, Martin Vechev*. PLDI 2021. [[PDF](https://dl.acm.org/doi/abs/10.1145/3453483.3454056)][theory]
28. **A Robust Adversarial Training Approach to Machine Reading Comprehension**. *Kai Liu, Xin Liu, An Yang, Jing Liu, Jinsong Su, Sujian Li, Qiaoqiao She*. PLDI 2021. [[PDF](https://dl.acm.org/doi/abs/10.1145/3453483.3454056)]
29. **SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions**. *Mao Ye, Chengyue Gong, Qiang Liu*. ACL 2020. [[PDF](https://arxiv.org/abs/2005.14424)]
30. **Combating Adversarial Misspellings with Robust Word Recognition**. *Danish Pruthi, Bhuwan Dhingra, Zachary C. Lipton*. ACL 2019. [[PDF](https://arxiv.org/abs/1905.11268)]
31. **Joint Character-Level Word Embedding and Adversarial Stability Training to Defend Adversarial Text**. *Hui Liu,  Yongzheng Zhang, Yipeng Wang, Zheng Lin, Yige Chen*. AAAI 2020. [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/6356)]
32. **Leveraging Adversarial Training in Self-Learning for Cross-Lingual Text Classification**. *Xin Dong, Yaxin Zhu, Yupeng Zhang, Zuohui Fu, Dongkuan Xu, Sen Yang, Gerard de Melo*. SIGIR 2020. [[PDF](https://dl.acm.org/doi/abs/10.1145/3397271.3401209)]
33. **NAT: Noise-Aware Training for Robust Neural Sequence Labeling**. *Marcin Namysl, Sven Behnke, Joachim Köhler*. ACL 2020. [[PDF](https://arxiv.org/abs/2005.07162)]
34. **Pretrained Transformers Improve Out-of-Distribution Robustness**. *Dan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic, Rishabh Krishnan, Dawn Song*. ACL 2020. [[PDF](https://arxiv.org/abs/2004.06100)]
35. **Robust Encodings: A Framework for Combating Adversarial Typos**. *Erik Jones, Robin Jia, Aditi Raghunathan, Percy Liang*. ACL 2020. [[PDF](https://arxiv.org/abs/2005.01229)]
36. **Robust Neural Machine Translation with Doubly Adversarial Inputs**. *Yong Cheng, Lu Jiang, Wolfgang Macherey*. ACL 2019. [[PDF](https://arxiv.org/abs/1906.02443)]
37. **TEXTSHIELD: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation**. *Jinfeng Li, Tianyu Du, Shouling Ji, Rong Zhang, Quan Lu, Min Yang, Ting Wang*. USENIX 2020. [[PDF](https://www.usenix.org/conference/usenixsecurity20/presentation/li-jinfeng)]
38. **Syntactic Data Augmentation Increases Robustness to Inference Heuristics**. *Junghyun Min, R. Thomas McCoy, Dipanjan Das, Emily Pitler, Tal Linzen*. ACL 2020. [[PDF](https://arxiv.org/abs/2004.11999)]
39. **Generating Adversarial Examples for Holding Robustness of Source Code Processing Models**. *Huangzhao Zhang, Zhuo Li, Ge Li, Lei Ma, Yang Liu, Zhi Jin*. AAAI 2020. [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/5469)]
40. **Attention Please: Your Attention Check Questions in Survey Studies Can Be Automatically Answered**. *Weiping Pei
, Arthur Mayer, Kaylynn Tu, Chuan Yue*. The Web Conference 2020. [[PDF](https://dl.acm.org/doi/abs/10.1145/3366423.3380195)]
40. **BERT & Family Eat Word Salad: Experiments with Text Understanding**. *Ashim Gupta, Giorgi Kvernadze, Vivek Srikumar*. AAAI 2021. [[PDF](https://www.aaai.org/AAAI21Papers/AAAI-10273.GuptaA.pdf)]
41. **Evaluating and Enhancing the Robustness of Neural Network-based Dependency Parsing Models with Adversarial Examples**. *Xiaoqing Zheng, Jiehang Zeng, Yi Zhou, Cho-Jui Hsieh, Minhao Cheng, Xuanjing Huang*. ACL 2020. [[PDF](https://aclanthology.org/2020.acl-main.590)]
42. **Imitation Attacks and Defenses for Black-box Machine Translation Systems**. *Eric Wallace, Mitchell Stern, Dawn Song*. EMNLP 2020. [[PDF](https://arxiv.org/abs/2004.15015)]
43. **Improving the Robustness of Question Answering Systems to Question Paraphrasing**. *Wee Chung Gan
, Hwee Tou Ng*. ACL 2019. [[PDF](https://aclanthology.org/P19-1610.pdf)]
44. **Crafting Adversarial Examples for Neural Machine Translation**. *Xinze Zhang, Junzhe Zhang, Zhenhua Chen, Kun He*. ACL 2021. [[PDF](https://aclanthology.org/2021.acl-long.153/)]
45. **Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks**. *Xiaosen Wang, Yichen Yang, Yihe Deng, Kun He*. AAAI 2021. [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/17648)]

### Compuper Vision
1. **Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning**. *Erwin Quiring, David Klein, Daniel Arp, Martin Johns, Konrad Rieck, TU Braunschweig*. USENIX 2020. [[PDF](https://www.usenix.org/conference/usenixsecurity20/presentation/quiring)]
2. **Amora: Black-box Adversarial Morphing Attack**. *Run Wang, Felix Juefei-Xu, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma, Yang Liu*. ACMMM 2020. [[PDF](https://dl.acm.org/doi/abs/10.1145/3394171.3413544)]
3. **Learning Ordered Top-k Adversarial Attacks via Adversarial Distillation**. *Zekun Zhang, Tianfu Wu*. CVPR 2020. [[PDF](https://openaccess.thecvf.com/content_CVPRW_2020/html/w47/Zhang_Learning_Ordered_Top-k_Adversarial_Attacks_via_Adversarial_Distillation_CVPRW_2020_paper.html)]
4. **Towards Feature Space Adversarial Attack by Style Perturbation**. *Qiuling Xu, Guanhong Tao, Siyuan Cheng, Xiangyu Zhang*. AAAI 2021. [[PDF](https://www.aaai.org/AAAI21Papers/AAAI-10011.XuQ.pdf)]
5. **Knowing When to Stop: Evaluation and Verification of Conformity to Output-size Specifications**. *Chenglong Wang, Rudy Bunel, Krishnamurthy Dvijotham, Po-Sen Huang, Edward Grefenstette, Pushmeet Kohli*. CVPR 2019. [[PDF](https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Knowing_When_to_Stop_Evaluation_and_Verification_of_Conformity_to_CVPR_2019_paper.html)]
6. **Defense Against Adversarial Images using Web-Scale Nearest-Neighbor Search**. *Abhimanyu Dubey, Laurens van der Maaten, Zeki Yalniz, Yixuan Li, Dhruv Mahajan*. CVPR 2019. [[PDF](https://openaccess.thecvf.com/content_CVPR_2019/html/Dubey_Defense_Against_Adversarial_Images_Using_Web-Scale_Nearest-Neighbor_Search_CVPR_2019_paper.html)]
7. **Evading Deepfake-Image Detectors with White- and Black-Box Attacks**. *Nicholas Carlini, Hany Farid*. CVPR 2020. [[PDF](https://openaccess.thecvf.com/content_CVPRW_2020/html/w39/Carlini_Evading_Deepfake-Image_Detectors_With_White-_and_Black-Box_Attacks_CVPRW_2020_paper.html)]
8. **Detecting Adversarial Samples Using Influence Functions and Nearest Neighbors**. *Gilad Cohen, Guillermo Sapiro, Raja Giryes*. CVPR 2020. [[PDF](https://ieeexplore.ieee.org/document/9157555/authors#full-text-header)]
9. **LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition**. *Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan, John P Dickerson, Gavin Taylor, Tom Goldstein*. ICLR 2021. [[PDF](https://openreview.net/forum?id=hJmtwocEqzc)]
10. **NIC: Detecting Adversarial Samples with Neural Network Invariant Checking**. *Shiqing Ma, Yingqi Liu, Guanhong Tao, Wen-Chuan Lee, Xiangyu Zhang*. NDSS 2019. [[PDF](https://www.ndss-symposium.org/ndss-paper/nic-detecting-adversarial-samples-with-neural-network-invariant-checking/)]
11. **Gotta Catch'Em All: Using Honeypots to Catch Adversarial Attacks on Neural Networks**. *Shawn Shan, Emily Wenger, Bolun Wang, Bo Li, Haitao Zheng, Ben Y. Zhao*. CCS 2020. [[PDF](https://dl.acm.org/doi/10.1145/3372297.3417231)]
12. **Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries**. *Fnu Suya, Jianfeng Chi, David Evans, Yuan Tian*. USENIX 2020. [[PDF](https://www.usenix.org/conference/usenixsecurity20/presentation/suya)]
13. **Stealthy Adversarial Perturbations Against  Real-Time Video Classification Systems**. *Shasha Li, Ajaya Neupane, Sujoy Paul, Chengyu Song, Srikanth V. Krishnamurthy, Amit K. Roy Chowdhury and Ananthram Swami*. NDSS 2019. [[PDF](https://www.ndss-symposium.org/ndss-paper/stealthy-adversarial-perturbations-against-real-time-video-classification-systems/)]
14. **Reinforcement Learning Based Sparse Black-box Adversarial Attack on Video Recognition Models**. *Zeyuan Wang, Chaofeng Sha, Su Yang*. IJCAI 2021. [[PDF](https://www.ijcai.org/proceedings/2021/435)]
15. **TkML-AP: Adversarial Attacks to Top-k Multi-Label Learning**. *Shu Hu, Lipeng Ke, Xin Wang, Siwei Lyu*. ICCV 2021. [[PDF](https://arxiv.org/abs/2108.00146)]

### Speech
1. **SirenAtack: Generating Adversarial Audio for End-to-End Acoustic Systems**. *Tianyu Du, Shouling Ji, Jinfeng Li, Qinchen Gu, Ting Wang, Raheem Beyah*. ASIA CCS 2020. [[PDF](https://dl.acm.org/doi/abs/10.1145/3320269.3384733)]
2. **Adversarial Music: Real World Audio Adversary Against Wake-word Detection System**. *Juncheng B. Li, Shuhui Qu, Xinjian Li, Joseph Szurley, J. Zico Kolter, Florian Metze*. NeurIPS 2019. [[PDF](https://arxiv.org/abs/1911.00126)]


## Related Workshops
1. [ICCV 2021 2nd Workshop on Adversarial Robustness In the Real World](https://iccv21-adv-workshop.github.io/)
2. [Uncertainty & Robustness in Deep Learning (Workshop at ICML 2021)](https://sites.google.com/view/udlworkshop2021/home)
3. [Security and Safety in Machine Learning Systems (Workshop at ICLR 2021)](https://aisecure-workshop.github.io/aml-iclr2021/)
4. [Generalization beyond the Training Distribution in Brains and Machines (Workshop at ICLR 2021)](https://iclr2021generalization.github.io/)
5. [1st International Workshop on Adversarial Learning for Multimedia (Workshop at ACM Multimedia 2021)](https://advm-workshop-2021.github.io/)
6. [Workshop on Adversarial Machine Learning in Real-World Computer Vision Systems and Online Challenges (Workshop at CVPR 2021)](https://aisecure-workshop.github.io/amlcvpr2021/)

## Team
1. Baoyuan Wu: **Secure Computing Lab of Big Data** http://scl.sribd.cn/index.html
2. Xingjun Ma: http://xingjunma.com/
3. Yang Liu: https://personal.ntu.edu.sg/yangliu/
4. Cihang Xie: https://cihangxie.github.io/
